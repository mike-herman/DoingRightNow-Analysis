{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `/DoingRightNow`\n"
     ]
    }
   ],
   "source": [
    "using Pkg;\n",
    "Pkg.activate(\".\");\n",
    "Pkg.instantiate();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames, Arrow, CategoricalArrays, ScientificTypes, MLJ, MLJBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE_PATH = \"./data/model_data.arrow\";\n",
    "df = DataFrame(Arrow.Table(DATA_FILE_PATH));\n",
    "df = copy(df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "function clean_data!(df)\n",
    "    \n",
    "    # Fix machine types.\n",
    "    HEFAMINC_ordered_set = [\n",
    "        \"Less than 5,000\",\n",
    "        \"5,000 to 7,499\",\n",
    "        \"7,500 to 9,999\",\n",
    "        \"10,000 to 12,499\",\n",
    "        \"12,500 to 14,999\",\n",
    "        \"15,000 to 19,999\",\n",
    "        \"20,000 to 24,999\",\n",
    "        \"25,000 to 29,999\",\n",
    "        \"30,000 to 34,999\",\n",
    "        \"35,000 to 39,999\",\n",
    "        \"40,000 to 49,999\",\n",
    "        \"50,000 to 59,999\",\n",
    "        \"60,000 to 74,999\",\n",
    "        \"75,000 to 99,999\",\n",
    "        \"100,000 to 149,999\",\n",
    "        \"150,000 and over\"\n",
    "    ]\n",
    "\n",
    "    df.TRTIER2 = categorical(df.TRTIER2)\n",
    "    df.GESTFIPS_label = categorical(df.GESTFIPS_label)\n",
    "    df.HEFAMINC_label = categorical(df.HEFAMINC_label; levels=HEFAMINC_ordered_set, ordered=true)\n",
    "    df.PEMARITL_label = categorical(df.PEMARITL_label)\n",
    "    df.HETENURE_label = categorical(df.HETENURE_label)\n",
    "    df.TUDIARYDAY_label = categorical(df.TUDIARYDAY_label)\n",
    "\n",
    "    # drop columns and disallow missing.\n",
    "    drop_cols = [\n",
    "        :TUCASEID,:TUACTIVITY_N,:TUSTARTTIM,:TUSTOPTIME,\n",
    "        :start_time_int,:stop_time_int,:TULINENO, :TUDIARYDAY\n",
    "        ]\n",
    "    select!(df, Not(drop_cols))\n",
    "    disallowmissing!(df)\n",
    "\n",
    "    # Define scientific types.\n",
    "    coerce!(df, :snap_time_int => Continuous, :PRTAGE => Continuous)\n",
    "end\n",
    "\n",
    "clean_data!(df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = unpack(df, ==(:TRTIER2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  2093636, 2093637, 2093638, 2093639, 2093640, 2093641, 2093642, 2093643, 2093644, 2093645], [2093646, 2093647, 2093648, 2093649, 2093650, 2093651, 2093652, 2093653, 2093654, 2093655  …  2617047, 2617048, 2617049, 2617050, 2617051, 2617052, 2617053, 2617054, 2617055, 2617056])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train, test = partition(eachindex(y), 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2093645-element CategoricalArray{Int64,1,UInt32}:\n",
       " 101\n",
       " 101\n",
       " 101\n",
       " 101\n",
       " 101\n",
       " 101\n",
       " 101\n",
       " 101\n",
       " 101\n",
       " 101\n",
       " ⋮\n",
       " 501\n",
       " 1203\n",
       " 101\n",
       " 1203\n",
       " 101\n",
       " 101\n",
       " 101\n",
       " 101\n",
       " 101"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test = X[test, :]\n",
    "X = X[train,:]\n",
    "\n",
    "y_test = y[test]\n",
    "y = y[train];"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the right model to use"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll take a look at what type of models are available to MLJ to predict on our target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in models(matching(X,y))\n",
    "    if m.prediction_type == :probabilistic\n",
    "        println(rpad(m.name, 30), \"($(m.package_name))\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only models showing are tree-based models. We're prodicting a multi-class category. And this is how it is encoded in the data. Tree-based models will handle this explicitly.\n",
    "\n",
    "But we _should_ be able to use something like a multivariate logistic regression, shouldn't we? Likely, the reason is typing. A regression isn't going to work on non-encoded predictors. According to the documentation, it _should_ properly interpret the multivariate target though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encode X into a new object called X2.\n",
    "ohe = OneHotEncoder(drop_last=true)\n",
    "mach = fit!(machine(ohe, X))\n",
    "X2 = MLJ.transform(mach, X)\n",
    "\n",
    "# Search for the available models.\n",
    "for m in models(matching(X2,y))\n",
    "    if m.prediction_type == :probabilistic\n",
    "        println(rpad(m.name, 30), \"($(m.package_name))\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a big variety of models to choose from.\n",
    "\n",
    "We'll start from the smaller list of tree-based models. The random forest is a good one. We can do this two ways -- by using the default `RandomForestClassifier` or by composing our own bagging of a set of `DecisionTreeClassifier` models.\n",
    "\n",
    "The easy, fast thing to do would be to use the default. But I'd like to get some practice in. So I'm going to do the bagging from scratch."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I continue, I'm going to partition the data into testing and training."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, a lot of this is adopted from [this MLJ documentation](https://alan-turing-institute.github.io/MLJ.jl/dev/tuning_models/#Tuning-multiple-nested-hyperparameters) and to a lesser extent from [this slightly outdated tutorial](https://juliaai.github.io/DataScienceTutorials.jl/getting-started/ensembles-2/)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DecisionTreeClassifier` from the `BetaML` package works with no encoding or transformation. But it takes a very long time to run. We'll try setting up a pipeline to transform the data ard run the `DecisionTreeClassifier` from the `DecisionTree` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models from packages.\n",
    "DecisionTreeClassifier = @load DecisionTreeClassifier pkg=DecisionTree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 -- Define a new model struct.\n",
    "\n",
    "Likely this is a probabalistic model. We'll need to confirm this and define a probabalistic network composite model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supertype(typeof(DecisionTreeClassifier()))    # Should be \"Probabilistic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new model struct.\n",
    "mutable struct CompositeA <: ProbabilisticNetworkComposite\n",
    "    preprocessor    # This part does the pre-processing.\n",
    "    classifier    # This part does the classifying\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 -- Create and wrap the learning network in `prefit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the above steps into a function called `prefit`\n",
    "import MLJBase    # We need to import in order to overload `MLJBase.prefit`\n",
    "function MLJBase.prefit(composite::CompositeA, verbosity, X, y)\n",
    "    # Define data input nodes. We just want the training set.\n",
    "    Xs = source(X[train,:])\n",
    "    ys = source(y[train])\n",
    "\n",
    "    # First machine -- We substitute the symbols in the struct defined above for the model objects.\n",
    "    mach1 = machine(:preprocessor, Xs)\n",
    "    x = MLJ.transform(mach1, Xs)    # `transform` has duplicated namespace. So we specify `MLJ.transform`\n",
    "    mach2 = machine(:classifier, x, ys)\n",
    "    ŷ = predict(mach2, x)\n",
    "\n",
    "    verbosity > 0 && @info \"I'm a noisy fellow!\"\n",
    "\n",
    "    #return \"learning network interface\":\n",
    "    return (; predict=ŷ)\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`prefit` always returns a _learning network interface_. Here, the inteface dictates that calling `predict(mach, Xnew)` on a machine `mach` bound to some instance of `CompositeA` should internally call `y\\hat(Xnew)`.\n",
    "\n",
    "\n",
    "This means we can use the above like any other model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLJ\n",
    "\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "tree = DecisionTreeClassifier(n_subfeatures=3)\n",
    "ensemble_model = EnsembleModel(model=tree, n=20)\n",
    "\n",
    "composite_a = CompositeA(one_hot_encoder,ensemble_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mach = machine(composite_a, X, y)\n",
    "#fit!(mach, rows=train, verbosity=0)\n",
    "estimates = evaluate!(mach, measure=cross_entropy)    # Equal to fit! then predict! then calling the measure."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Hyperparameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by tuning the `tree.n_subfeatures` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_n_subfeatures = range(composite_a, :(classifier.model.n_subfeatures),lower=1, upper=6)\n",
    "tuned_composite_a = TunedModel(\n",
    "    composite_a,\n",
    "    range=r_n_subfeatures,\n",
    "    tuning=RandomSearch(rng=123),\n",
    "    measure=cross_entropy,\n",
    "    resampling=CV(nfolds=6),\n",
    "    n=100,\n",
    ")\n",
    "mach = machine(tuned_composite_a, X, y) |> fit!\n",
    "report(mach).best_model\n",
    "# estimates2 = evaluate!(mach, measure=cross_entropy)    # Equal to fit! then predict! then calling the measure."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That takes way too long. I even tried it on my gaming PC and throwing compute at it doesn't fix the problem.\n",
    "\n",
    "Let's try the out-of-the-box RandomForest model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out-of-the-box Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main /root/.julia/packages/MLJModels/UM8fF/src/loading.jl:159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJDecisionTreeInterface ✔"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLJDecisionTreeInterface.RandomForestClassifier"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load models from packages.\n",
    "RandomForestClassifier = @load RandomForestClassifier pkg=DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new model struct.\n",
    "mutable struct ATUSRandomForest <: ProbabilisticNetworkComposite\n",
    "    preprocessor    # This part does the pre-processing.\n",
    "    classifier    # This part does the classifying\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prefit\n",
    "import MLJBase\n",
    "function MLJBase.prefit(composite::ATUSRandomForest, verbosity, X, y)\n",
    "\n",
    "    # Learning network\n",
    "    Xs = source(X)\n",
    "    ys = source(y)\n",
    "    mach1 = machine(:preprocessor, Xs)\n",
    "    x = MLJ.transform(mach1, Xs)\n",
    "    mach2 = machine(:classifier, x, ys)\n",
    "    yhat = predict(mach2, x)\n",
    "\n",
    "    verbosity > 0 && @info \"I sure am noisy\"\n",
    "\n",
    "    # return \"learning network interface\":\n",
    "    return (; predict=yhat)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ATUSRandomForest(\n",
       "  preprocessor = OneHotEncoder(\n",
       "        features = Symbol[], \n",
       "        drop_last = false, \n",
       "        ordered_factor = true, \n",
       "        ignore = false), \n",
       "  classifier = RandomForestClassifier(\n",
       "        max_depth = 10, \n",
       "        min_samples_leaf = 1, \n",
       "        min_samples_split = 2, \n",
       "        min_purity_increase = 0.0, \n",
       "        n_subfeatures = 12, \n",
       "        n_trees = 100, \n",
       "        sampling_fraction = 0.3, \n",
       "        feature_importance = :impurity, \n",
       "        rng = 71))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "one_hot_encoder = OneHotEncoder()\n",
    "forest = RandomForestClassifier(\n",
    "    n_subfeatures=12,\n",
    "    sampling_fraction=0.3,    # We have lots of data. Only use 30%.\n",
    "    max_depth=10,\n",
    "    rng=71\n",
    "    )\n",
    "\n",
    "atus_random_forest = ATUSRandomForest(one_hot_encoder,forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training machine(ATUSRandomForest(preprocessor = OneHotEncoder(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase /root/.julia/packages/MLJBase/g5E7V/src/machines.jl:492\n",
      "┌ Info: I sure am noisy\n",
      "└ @ Main /DoingRightNow/atus_ml_model.ipynb:13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training machine(:preprocessor, …).\n",
      "└ @ MLJBase /root/.julia/packages/MLJBase/g5E7V/src/machines.jl:492\n",
      "┌ Info: Spawning 51 sub-features to one-hot encode feature :GESTFIPS_label.\n",
      "└ @ MLJModels /root/.julia/packages/MLJModels/UM8fF/src/builtins/Transformers.jl:878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Spawning 16 sub-features to one-hot encode feature :HEFAMINC_label.\n",
      "└ @ MLJModels /root/.julia/packages/MLJModels/UM8fF/src/builtins/Transformers.jl:878\n",
      "┌ Info: Spawning 2 sub-features to one-hot encode feature :PEMARITL_label.\n",
      "└ @ MLJModels /root/.julia/packages/MLJModels/UM8fF/src/builtins/Transformers.jl:878\n",
      "┌ Info: Spawning 3 sub-features to one-hot encode feature :HETENURE_label.\n",
      "└ @ MLJModels /root/.julia/packages/MLJModels/UM8fF/src/builtins/Transformers.jl:878\n",
      "┌ Info: Spawning 7 sub-features to one-hot encode feature :TUDIARYDAY_label.\n",
      "└ @ MLJModels /root/.julia/packages/MLJModels/UM8fF/src/builtins/Transformers.jl:878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training machine(:classifier, …).\n",
      "└ @ MLJBase /root/.julia/packages/MLJBase/g5E7V/src/machines.jl:492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "trained Machine; does not cache data\n",
       "  model: ATUSRandomForest(preprocessor = OneHotEncoder(features = Symbol[], …), …)\n",
       "  args: \n",
       "    1:\tSource @887 ⏎ Table{Union{AbstractVector{Continuous}, AbstractVector{Multiclass{51}}, AbstractVector{Multiclass{2}}, AbstractVector{Multiclass{3}}, AbstractVector{Multiclass{7}}, AbstractVector{OrderedFactor{16}}}}\n",
       "    2:\tSource @137 ⏎ AbstractVector{Multiclass{99}}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mach = machine(atus_random_forest, X, y)\n",
    "fit!(mach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "523411-element UnivariateFiniteVector{Multiclass{99}, Int64, UInt32, Float64}:\n",
       " UnivariateFinite{Multiclass{99}}(101=>0.35, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.0, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.65, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>0.27, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.0, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.01, 1202=>0.0, 1203=>0.72, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>0.34, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.0, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.66, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>0.35, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.01, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.32, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.32, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>0.28, 102=>0.0, 103=>0.01, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.0, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.71, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>0.5, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.02, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.48, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>0.57, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.01, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.42, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>0.31, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.01, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.42, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.26, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>0.36, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.31, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.33, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>0.23, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.06, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.71, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " ⋮\n",
       " UnivariateFinite{Multiclass{99}}(101=>0.18, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.0, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.82, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>0.41, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.01, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.31, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.27, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>0.17, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.12, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.71, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>0.26, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.01, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.73, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>0.29, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.3, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.41, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>0.22, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.12, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.66, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>0.45, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.0, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.55, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>0.31, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.4, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.29, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>0.3, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.4, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.3, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ŷ = predict(mach, X_test)\n",
    "#MulticlassFScore()(ŷ, y[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9817923871429786"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean(cross_entropy(ŷ, y_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross_entropy for this is 1.98179"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try clustering the predictors first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ATUSClusterClassifier(\n",
       "  one_hot_encoder = OneHotEncoder(\n",
       "        features = Symbol[], \n",
       "        drop_last = true, \n",
       "        ordered_factor = false, \n",
       "        ignore = false), \n",
       "  clusterer = DBSCAN(\n",
       "        radius = 1.0, \n",
       "        leafsize = 20, \n",
       "        min_neighbors = 1, \n",
       "        min_cluster_size = 288), \n",
       "  classifier = RandomForestClassifier(\n",
       "        max_depth = 10, \n",
       "        min_samples_leaf = 1, \n",
       "        min_samples_split = 2, \n",
       "        min_purity_increase = 0.0, \n",
       "        n_subfeatures = 12, \n",
       "        n_trees = 100, \n",
       "        sampling_fraction = 0.3, \n",
       "        feature_importance = :impurity, \n",
       "        rng = 71))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load models from packages.\n",
    "DBSCAN = @load DBSCAN pkg=Clustering verbosity=0\n",
    "\n",
    "# Define a new model struct.\n",
    "mutable struct ATUSClusterClassifier <: ProbabilisticNetworkComposite\n",
    "    one_hot_encoder    # This part does the pre-processing.\n",
    "    clusterer    # This part clusters the predictors.\n",
    "    classifier    # This part does the classifying\n",
    "end\n",
    "\n",
    "# Create prefit\n",
    "function MLJBase.prefit(composite::ATUSClusterClassifier, verbosity, X, y)\n",
    "\n",
    "    verbosity > 0 && @info \"Running ATUSClusterClassifier composite model.\"\n",
    "\n",
    "    # Learning network\n",
    "    Xs = source(X)\n",
    "    ys = source(y)\n",
    "    ## Transform categoricals using one-hot-encoding.\n",
    "    mach_ohe = machine(:one_hot_encoder, Xs)\n",
    "    x_proc = MLJ.transform(mach_ohe, Xs)\n",
    "    ## Cluster predictors. Produces a single categorical vector.\n",
    "    mach_clust = machine(:clusterer, x_proc)\n",
    "    x_clust = predict(mach_clust, x_proc)\n",
    "    ## One hot encode the cluster vector.\n",
    "    mach_clust_ohe = machine(:one_hot_encoder, x_clust)\n",
    "    x_clust_ohe = MLJ.transform(mach_clust_ohe, x_clust)\n",
    "    ## Run the classifier and predict.\n",
    "    mach_class = machine(:classifier, x_clust, ys)\n",
    "    yhat = predict(mach_class, x_clust)\n",
    "\n",
    "    # return \"learning network interface\":\n",
    "    return (; predict=yhat)\n",
    "\n",
    "end\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(ordered_factor=false, drop_last=true)\n",
    "dbscan = DBSCAN(min_cluster_size=288)    # Each individual has 288 observations. A little arbitrary.\n",
    "forest = RandomForestClassifier(\n",
    "    n_subfeatures=12,\n",
    "    sampling_fraction=0.3,    # We have lots of data. Only use 30%.\n",
    "    max_depth=10,\n",
    "    rng=71\n",
    "    )\n",
    "\n",
    "atus_cluster_classifier = ATUSClusterClassifier(one_hot_encoder, dbscan,forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training machine(ATUSClusterClassifier(one_hot_encoder = OneHotEncoder(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase /root/.julia/packages/MLJBase/g5E7V/src/machines.jl:492\n",
      "┌ Info: I sure am noisy\n",
      "└ @ Main /DoingRightNow/atus_ml_model.ipynb:30\n"
     ]
    }
   ],
   "source": [
    "mach = machine(atus_cluster_classifier, X, y)\n",
    "fit!(mach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ŷ = predict(mach, X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
