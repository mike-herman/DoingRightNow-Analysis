{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Repos/DoingRightNow-Analysis`\n"
     ]
    }
   ],
   "source": [
    "using Pkg;\n",
    "Pkg.activate(\".\");\n",
    "Pkg.instantiate();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames, Arrow, CategoricalArrays, ScientificTypes, MLJ, MLJBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE_PATH = \"./data/model_data.arrow\";\n",
    "df = DataFrame(Arrow.Table(DATA_FILE_PATH));\n",
    "df = copy(df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "function clean_data!(df)\n",
    "    \n",
    "    # Fix machine types.\n",
    "    HEFAMINC_ordered_set = [\n",
    "        \"Less than 5,000\",\n",
    "        \"5,000 to 7,499\",\n",
    "        \"7,500 to 9,999\",\n",
    "        \"10,000 to 12,499\",\n",
    "        \"12,500 to 14,999\",\n",
    "        \"15,000 to 19,999\",\n",
    "        \"20,000 to 24,999\",\n",
    "        \"25,000 to 29,999\",\n",
    "        \"30,000 to 34,999\",\n",
    "        \"35,000 to 39,999\",\n",
    "        \"40,000 to 49,999\",\n",
    "        \"50,000 to 59,999\",\n",
    "        \"60,000 to 74,999\",\n",
    "        \"75,000 to 99,999\",\n",
    "        \"100,000 to 149,999\",\n",
    "        \"150,000 and over\"\n",
    "    ]\n",
    "\n",
    "    df.TRTIER2 = categorical(df.TRTIER2)\n",
    "    df.GESTFIPS_label = categorical(df.GESTFIPS_label)\n",
    "    df.HEFAMINC_label = categorical(df.HEFAMINC_label; levels=HEFAMINC_ordered_set, ordered=true)\n",
    "    df.PEMARITL_label = categorical(df.PEMARITL_label)\n",
    "    df.HETENURE_label = categorical(df.HETENURE_label)\n",
    "    df.TUDIARYDAY_label = categorical(df.TUDIARYDAY_label)\n",
    "\n",
    "    # drop columns and disallow missing.\n",
    "    drop_cols = [\n",
    "        :TUCASEID,:TUACTIVITY_N,:TUSTARTTIM,:TUSTOPTIME,\n",
    "        :start_time_int,:stop_time_int,:TULINENO, :TUDIARYDAY\n",
    "        ]\n",
    "    select!(df, Not(drop_cols))\n",
    "    disallowmissing!(df)\n",
    "\n",
    "    # Define scientific types.\n",
    "    coerce!(df, :snap_time_int => Continuous, :PRTAGE => Continuous)\n",
    "end\n",
    "\n",
    "clean_data!(df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = unpack(df, ==(:TRTIER2));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  2093636, 2093637, 2093638, 2093639, 2093640, 2093641, 2093642, 2093643, 2093644, 2093645], [2093646, 2093647, 2093648, 2093649, 2093650, 2093651, 2093652, 2093653, 2093654, 2093655  …  2617047, 2617048, 2617049, 2617050, 2617051, 2617052, 2617053, 2617054, 2617055, 2617056])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train, test = partition(eachindex(y), 0.8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the right model to use"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll take a look at what type of models are available to MLJ to predict on our target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in models(matching(X,y))\n",
    "    if m.prediction_type == :probabilistic\n",
    "        println(rpad(m.name, 30), \"($(m.package_name))\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only models showing are tree-based models. We're prodicting a multi-class category. And this is how it is encoded in the data. Tree-based models will handle this explicitly.\n",
    "\n",
    "But we _should_ be able to use something like a multivariate logistic regression, shouldn't we? Likely, the reason is typing. A regression isn't going to work on non-encoded predictors. According to the documentation, it _should_ properly interpret the multivariate target though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encode X into a new object called X2.\n",
    "ohe = OneHotEncoder(drop_last=true)\n",
    "mach = fit!(machine(ohe, X))\n",
    "X2 = MLJ.transform(mach, X)\n",
    "\n",
    "# Search for the available models.\n",
    "for m in models(matching(X2,y))\n",
    "    if m.prediction_type == :probabilistic\n",
    "        println(rpad(m.name, 30), \"($(m.package_name))\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a big variety of models to choose from.\n",
    "\n",
    "We'll start from the smaller list of tree-based models. The random forest is a good one. We can do this two ways -- by using the default `RandomForestClassifier` or by composing our own bagging of a set of `DecisionTreeClassifier` models.\n",
    "\n",
    "The easy, fast thing to do would be to use the default. But I'd like to get some practice in. So I'm going to do the bagging from scratch."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I continue, I'm going to partition the data into testing and training."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, a lot of this is adopted from [this MLJ documentation](https://alan-turing-institute.github.io/MLJ.jl/dev/tuning_models/#Tuning-multiple-nested-hyperparameters) and to a lesser extent from [this slightly outdated tutorial](https://juliaai.github.io/DataScienceTutorials.jl/getting-started/ensembles-2/)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DecisionTreeClassifier` from the `BetaML` package works with no encoding or transformation. But it takes a very long time to run. We'll try setting up a pipeline to transform the data ard run the `DecisionTreeClassifier` from the `DecisionTree` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models from packages.\n",
    "DecisionTreeClassifier = @load DecisionTreeClassifier pkg=DecisionTree"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 -- Define a new model struct.\n",
    "\n",
    "Likely this is a probabalistic model. We'll need to confirm this and define a probabalistic network composite model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supertype(typeof(DecisionTreeClassifier()))    # Should be \"Probabilistic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new model struct.\n",
    "mutable struct CompositeA <: ProbabilisticNetworkComposite\n",
    "    preprocessor    # This part does the pre-processing.\n",
    "    classifier    # This part does the classifying\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 -- Create and wrap the learning network in `prefit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the above steps into a function called `prefit`\n",
    "import MLJBase    # We need to import in order to overload `MLJBase.prefit`\n",
    "function MLJBase.prefit(composite::CompositeA, verbosity, X, y)\n",
    "    # Define data input nodes. We just want the training set.\n",
    "    Xs = source(X[train,:])\n",
    "    ys = source(y[train])\n",
    "\n",
    "    # First machine -- We substitute the symbols in the struct defined above for the model objects.\n",
    "    mach1 = machine(:preprocessor, Xs)\n",
    "    x = MLJ.transform(mach1, Xs)    # `transform` has duplicated namespace. So we specify `MLJ.transform`\n",
    "    mach2 = machine(:classifier, x, ys)\n",
    "    ŷ = predict(mach2, x)\n",
    "\n",
    "    verbosity > 0 && @info \"I'm a noisy fellow!\"\n",
    "\n",
    "    #return \"learning network interface\":\n",
    "    return (; predict=ŷ)\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`prefit` always returns a _learning network interface_. Here, the inteface dictates that calling `predict(mach, Xnew)` on a machine `mach` bound to some instance of `CompositeA` should internally call `y\\hat(Xnew)`.\n",
    "\n",
    "\n",
    "This means we can use the above like any other model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLJ\n",
    "\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "tree = DecisionTreeClassifier(n_subfeatures=3)\n",
    "ensemble_model = EnsembleModel(model=tree, n=20)\n",
    "\n",
    "composite_a = CompositeA(one_hot_encoder,ensemble_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mach = machine(composite_a, X, y)\n",
    "#fit!(mach, rows=train, verbosity=0)\n",
    "estimates = evaluate!(mach, measure=cross_entropy)    # Equal to fit! then predict! then calling the measure."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Hyperparameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by tuning the `tree.n_subfeatures` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_n_subfeatures = range(composite_a, :(classifier.model.n_subfeatures),lower=1, upper=6)\n",
    "tuned_composite_a = TunedModel(\n",
    "    composite_a,\n",
    "    range=r_n_subfeatures,\n",
    "    tuning=RandomSearch(rng=123),\n",
    "    measure=cross_entropy,\n",
    "    resampling=CV(nfolds=6),\n",
    "    n=100,\n",
    ")\n",
    "mach = machine(tuned_composite_a, X, y) |> fit!\n",
    "report(mach).best_model\n",
    "# estimates2 = evaluate!(mach, measure=cross_entropy)    # Equal to fit! then predict! then calling the measure."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That takes way too long. I even tried it on my gaming PC and throwing compute at it doesn't fix the problem.\n",
    "\n",
    "Let's try the out-of-the-box RandomForest model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out-of-the-box Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main /Users/mph/.julia/packages/MLJModels/UM8fF/src/loading.jl:159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJDecisionTreeInterface ✔"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLJDecisionTreeInterface.RandomForestClassifier"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load models from packages.\n",
    "RandomForestClassifier = @load RandomForestClassifier pkg=DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new model struct.\n",
    "mutable struct ATUSRandomForest <: ProbabilisticNetworkComposite\n",
    "    preprocessor    # This part does the pre-processing.\n",
    "    classifier    # This part does the classifying\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prefit\n",
    "import MLJBase\n",
    "function MLJBase.prefit(composite::ATUSRandomForest, verbosity, X, y)\n",
    "\n",
    "    # Learning network\n",
    "    Xs = source(X)\n",
    "    ys = source(y)\n",
    "    mach1 = machine(:preprocessor, Xs)\n",
    "    x = MLJ.transform(mach1, Xs)\n",
    "    mach2 = machine(:classifier, x, ys)\n",
    "    yhat = predict(mach2, x)\n",
    "\n",
    "    verbosity > 0 && @info \"I sure am noisy\"\n",
    "\n",
    "    # return \"learning network interface\":\n",
    "    return (; predict=yhat)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ATUSRandomForest(\n",
       "  preprocessor = OneHotEncoder(\n",
       "        features = Symbol[], \n",
       "        drop_last = false, \n",
       "        ordered_factor = true, \n",
       "        ignore = false), \n",
       "  classifier = RandomForestClassifier(\n",
       "        max_depth = 10, \n",
       "        min_samples_leaf = 1, \n",
       "        min_samples_split = 2, \n",
       "        min_purity_increase = 0.0, \n",
       "        n_subfeatures = 12, \n",
       "        n_trees = 100, \n",
       "        sampling_fraction = 0.3, \n",
       "        feature_importance = :impurity, \n",
       "        rng = 71))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "one_hot_encoder = OneHotEncoder()\n",
    "forest = RandomForestClassifier(\n",
    "    n_subfeatures=12,\n",
    "    sampling_fraction=0.3,    # We have lots of data. Only use 30%.\n",
    "    max_depth=10,\n",
    "    rng=71\n",
    "    )\n",
    "\n",
    "atus_random_forest = ATUSRandomForest(one_hot_encoder,forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training machine(ATUSRandomForest(preprocessor = OneHotEncoder(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase /Users/mph/.julia/packages/MLJBase/g5E7V/src/machines.jl:492\n",
      "┌ Info: I sure am noisy\n",
      "└ @ Main /Users/mph/Repos/DoingRightNow-Analysis/atus_ml_model.ipynb:13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training machine(:preprocessor, …).\n",
      "└ @ MLJBase /Users/mph/.julia/packages/MLJBase/g5E7V/src/machines.jl:492\n",
      "┌ Info: Spawning 51 sub-features to one-hot encode feature :GESTFIPS_label.\n",
      "└ @ MLJModels /Users/mph/.julia/packages/MLJModels/UM8fF/src/builtins/Transformers.jl:878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Spawning 16 sub-features to one-hot encode feature :HEFAMINC_label.\n",
      "└ @ MLJModels /Users/mph/.julia/packages/MLJModels/UM8fF/src/builtins/Transformers.jl:878\n",
      "┌ Info: Spawning 2 sub-features to one-hot encode feature :PEMARITL_label.\n",
      "└ @ MLJModels /Users/mph/.julia/packages/MLJModels/UM8fF/src/builtins/Transformers.jl:878\n",
      "┌ Info: Spawning 3 sub-features to one-hot encode feature :HETENURE_label.\n",
      "└ @ MLJModels /Users/mph/.julia/packages/MLJModels/UM8fF/src/builtins/Transformers.jl:878\n",
      "┌ Info: Spawning 7 sub-features to one-hot encode feature :TUDIARYDAY_label.\n",
      "└ @ MLJModels /Users/mph/.julia/packages/MLJModels/UM8fF/src/builtins/Transformers.jl:878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training machine(:classifier, …).\n",
      "└ @ MLJBase /Users/mph/.julia/packages/MLJBase/g5E7V/src/machines.jl:492\n"
     ]
    },
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: test not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: test not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ ~/Repos/DoingRightNow-Analysis/atus_ml_model.ipynb:3"
     ]
    }
   ],
   "source": [
    "mach = machine(atus_random_forest, X, y)\n",
    "fit!(mach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "523411-element UnivariateFiniteVector{Multiclass{99}, Int64, UInt32, Float64}:\n",
       " UnivariateFinite{Multiclass{99}}(101=>1.0, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.0, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.0, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>0.99, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.0, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.01, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>1.0, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.0, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.0, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>0.98, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.0, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.02, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>1.0, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.0, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.0, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>0.99, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.0, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.01, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>1.0, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.0, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.0, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>1.0, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.0, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.0, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>0.99, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.01, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.0, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>1.0, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.0, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.0, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " ⋮\n",
       " UnivariateFinite{Multiclass{99}}(101=>1.0, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.0, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.0, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>1.0, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.0, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.0, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>1.0, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.0, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.0, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>1.0, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.0, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.0, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>1.0, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.0, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.0, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>1.0, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.0, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.0, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>1.0, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.0, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.0, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>1.0, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.0, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.0, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)\n",
       " UnivariateFinite{Multiclass{99}}(101=>1.0, 102=>0.0, 103=>0.0, 104=>0.0, 105=>0.0, 201=>0.0, 202=>0.0, 203=>0.0, 204=>0.0, 205=>0.0, 206=>0.0, 207=>0.0, 208=>0.0, 209=>0.0, 299=>0.0, 301=>0.0, 302=>0.0, 303=>0.0, 304=>0.0, 305=>0.0, 399=>0.0, 401=>0.0, 402=>0.0, 403=>0.0, 404=>0.0, 405=>0.0, 499=>0.0, 501=>0.0, 502=>0.0, 503=>0.0, 504=>0.0, 599=>0.0, 601=>0.0, 602=>0.0, 603=>0.0, 604=>0.0, 699=>0.0, 701=>0.0, 702=>0.0, 801=>0.0, 802=>0.0, 803=>0.0, 804=>0.0, 805=>0.0, 806=>0.0, 807=>0.0, 899=>0.0, 901=>0.0, 902=>0.0, 903=>0.0, 904=>0.0, 905=>0.0, 999=>0.0, 1001=>0.0, 1002=>0.0, 1003=>0.0, 1004=>0.0, 1101=>0.0, 1102=>0.0, 1201=>0.0, 1202=>0.0, 1203=>0.0, 1204=>0.0, 1205=>0.0, 1301=>0.0, 1302=>0.0, 1303=>0.0, 1401=>0.0, 1499=>0.0, 1501=>0.0, 1502=>0.0, 1503=>0.0, 1504=>0.0, 1505=>0.0, 1506=>0.0, 1507=>0.0, 1508=>0.0, 1599=>0.0, 1601=>0.0, 1602=>0.0, 1801=>0.0, 1802=>0.0, 1803=>0.0, 1804=>0.0, 1805=>0.0, 1806=>0.0, 1807=>0.0, 1808=>0.0, 1809=>0.0, 1810=>0.0, 1811=>0.0, 1812=>0.0, 1813=>0.0, 1814=>0.0, 1815=>0.0, 1816=>0.0, 1818=>0.0, 1899=>0.0, 5001=>0.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ŷ = predict(mach, X[test,:])\n",
    "#MulticlassFScore()(ŷ, y[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "523411-element Vector{Float64}:\n",
       " 36.04365338911715\n",
       "  0.01005033585350145\n",
       "  2.220446049250313e-16\n",
       "  3.912023005428146\n",
       "  2.220446049250313e-16\n",
       "  0.01005033585350145\n",
       "  2.220446049250313e-16\n",
       " 36.04365338911715\n",
       "  0.01005033585350145\n",
       "  2.220446049250313e-16\n",
       "  ⋮\n",
       "  2.220446049250313e-16\n",
       "  2.220446049250313e-16\n",
       "  2.220446049250313e-16\n",
       "  2.220446049250313e-16\n",
       "  2.220446049250313e-16\n",
       "  2.220446049250313e-16\n",
       "  2.220446049250313e-16\n",
       "  2.220446049250313e-16\n",
       "  2.220446049250313e-16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cross_entropy(ŷ, y[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AbstractVector{Multiclass{99}}\u001b[90m (alias for \u001b[39m\u001b[90mAbstractArray{Multiclass{99}, 1}\u001b[39m\u001b[90m)\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scitype(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema(DataFrame(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: The number and/or types of data arguments do not match what the specified model\n",
      "│ supports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "│ \n",
      "│ Run `@doc MLJModels.OneHotEncoder` to learn more about your model's requirements.\n",
      "│ \n",
      "│ Commonly, but non exclusively, supervised models are constructed using the syntax\n",
      "│ `machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "│ constructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "│ sample or class weights.\n",
      "│ \n",
      "│ In general, data in `machine(model, data...)` is expected to satisfy\n",
      "│ \n",
      "│     scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "│ \n",
      "│ In the present case:\n",
      "│ \n",
      "│ scitype(data) = Tuple{AbstractVector{Multiclass{99}}}\n",
      "│ \n",
      "│ fit_data_scitype(model) = Tuple{Table}\n",
      "└ @ MLJBase /Users/mph/.julia/packages/MLJBase/g5E7V/src/machines.jl:230\n",
      "┌ Info: Training machine(OneHotEncoder(features = Symbol[], …), …).\n",
      "└ @ MLJBase /Users/mph/.julia/packages/MLJBase/g5E7V/src/machines.jl:492\n",
      "┌ Error: Problem fitting the machine machine(OneHotEncoder(features = Symbol[], …), …). \n",
      "└ @ MLJBase /Users/mph/.julia/packages/MLJBase/g5E7V/src/machines.jl:682\n",
      "┌ Info: Running type checks... \n",
      "└ @ MLJBase /Users/mph/.julia/packages/MLJBase/g5E7V/src/machines.jl:688\n",
      "┌ Warning: The number and/or types of data arguments do not match what the specified model\n",
      "│ supports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "│ \n",
      "│ Run `@doc MLJModels.OneHotEncoder` to learn more about your model's requirements.\n",
      "│ \n",
      "│ Commonly, but non exclusively, supervised models are constructed using the syntax\n",
      "│ `machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "│ constructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "│ sample or class weights.\n",
      "│ \n",
      "│ In general, data in `machine(model, data...)` is expected to satisfy\n",
      "│ \n",
      "│     scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "│ \n",
      "│ In the present case:\n",
      "│ \n",
      "│ scitype(data) = Tuple{AbstractVector{Multiclass{99}}}\n",
      "│ \n",
      "│ fit_data_scitype(model) = Tuple{Table}\n",
      "└ @ MLJBase /Users/mph/.julia/packages/MLJBase/g5E7V/src/machines.jl:230\n",
      "┌ Info: It seems an upstream node in a learning network is providing data of incompatible scitype. See above. \n",
      "└ @ MLJBase /Users/mph/.julia/packages/MLJBase/g5E7V/src/machines.jl:694\n"
     ]
    },
    {
     "ename": "ErrorException",
     "evalue": "type Nothing has no field names",
     "output_type": "error",
     "traceback": [
      "type Nothing has no field names\n",
      "\n",
      "Stacktrace:\n",
      " [1] getproperty(x::Nothing, f::Symbol)\n",
      "   @ Base ./Base.jl:38\n",
      " [2] fit(transformer::OneHotEncoder, verbosity::Int64, X::CategoricalVector{Int64, UInt32, Int64, CategoricalValue{Int64, UInt32}, Union{}})\n",
      "   @ MLJModels ~/.julia/packages/MLJModels/UM8fF/src/builtins/Transformers.jl:843\n",
      " [3] fit_only!(mach::Machine{OneHotEncoder, true}; rows::Nothing, verbosity::Int64, force::Bool, composite::Nothing)\n",
      "   @ MLJBase ~/.julia/packages/MLJBase/g5E7V/src/machines.jl:680\n",
      " [4] fit_only!\n",
      "   @ ~/.julia/packages/MLJBase/g5E7V/src/machines.jl:606 [inlined]\n",
      " [5] #fit!#63\n",
      "   @ ~/.julia/packages/MLJBase/g5E7V/src/machines.jl:778 [inlined]\n",
      " [6] fit!\n",
      "   @ ~/.julia/packages/MLJBase/g5E7V/src/machines.jl:775 [inlined]\n",
      " [7] |>(x::Machine{OneHotEncoder, true}, f::typeof(fit!))\n",
      "   @ Base ./operators.jl:911\n",
      " [8] top-level scope\n",
      "   @ ~/Repos/DoingRightNow-Analysis/atus_ml_model.ipynb:1"
     ]
    }
   ],
   "source": [
    "mach_y_ohe = machine(OneHotEncoder(),y) |> fit!\n",
    "#y_ohe = MLJ.transform(mach_y_ohe, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "ArgumentError: CategoricalArray only supports AbstractString, AbstractChar and Number element types (got element type UnivariateFinite{Multiclass{99}, Int64, UInt32, Float64})",
     "output_type": "error",
     "traceback": [
      "ArgumentError: CategoricalArray only supports AbstractString, AbstractChar and Number element types (got element type UnivariateFinite{Multiclass{99}, Int64, UInt32, Float64})\n",
      "\n",
      "Stacktrace:\n",
      " [1] check_supported_eltype(#unused#::Type{UnivariateFinite{Multiclass{99}, Int64, UInt32, Float64}}, #unused#::Type{UnivariateFinite{Multiclass{99}, Int64, UInt32, Float64}})\n",
      "   @ CategoricalArrays ~/.julia/packages/CategoricalArrays/tJ8hD/src/array.jl:29\n",
      " [2] fixtype(A::UnivariateFiniteVector{Multiclass{99}, Int64, UInt32, Float64})\n",
      "   @ CategoricalArrays ~/.julia/packages/CategoricalArrays/tJ8hD/src/array.jl:45\n",
      " [3] #categorical#65\n",
      "   @ ~/.julia/packages/CategoricalArrays/tJ8hD/src/array.jl:1028 [inlined]\n",
      " [4] _categorical(y1::UnivariateFiniteVector{Multiclass{99}, Int64, UInt32, Float64}, y2::CategoricalVector{Int64, UInt32, Int64, CategoricalValue{Int64, UInt32}, Union{}})\n",
      "   @ MLJBase ~/.julia/packages/MLJBase/g5E7V/src/measures/confusion_matrix.jl:40\n",
      " [5] _confmat(ŷraw::UnivariateFiniteVector{Multiclass{99}, Int64, UInt32, Float64}, yraw::CategoricalVector{Int64, UInt32, Int64, CategoricalValue{Int64, UInt32}, Union{}}; rev::Nothing, perm::Nothing, warn::Bool)\n",
      "   @ MLJBase ~/.julia/packages/MLJBase/g5E7V/src/measures/confusion_matrix.jl:94\n",
      " [6] call(m::ConfusionMatrix, ŷ::UnivariateFiniteVector{Multiclass{99}, Int64, UInt32, Float64}, y::CategoricalVector{Int64, UInt32, Int64, CategoricalValue{Int64, UInt32}, Union{}})\n",
      "   @ MLJBase ~/.julia/packages/MLJBase/g5E7V/src/measures/confusion_matrix.jl:261\n",
      " [7] (::ConfusionMatrix)(::UnivariateFiniteVector{Multiclass{99}, Int64, UInt32, Float64}, ::Vararg{Any})\n",
      "   @ MLJBase ~/.julia/packages/MLJBase/g5E7V/src/measures/measures.jl:133\n",
      " [8] top-level scope\n",
      "   @ ~/Repos/DoingRightNow-Analysis/atus_ml_model.ipynb:1"
     ]
    }
   ],
   "source": [
    "cmat = ConfusionMatrix()(ŷ,y[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Vector{NamedTuple{(:name, :instances, :human_name, :target_scitype, :supports_weights, :supports_class_weights, :prediction_type, :orientation, :reports_each_observation, :aggregation, :is_feature_dependent, :docstring, :distribution_type)}}:\n",
       " (name = ConfusionMatrix, instances = [confusion_matrix, confmat], ...)\n",
       " (name = HuberLoss, instances = [huber_loss], ...)\n",
       " (name = L1EpsilonInsLoss, instances = [l1_epsilon_ins_loss], ...)\n",
       " (name = L2EpsilonInsLoss, instances = [l2_epsilon_ins_loss], ...)\n",
       " (name = LPDistLoss, instances = [lp_dist_loss], ...)\n",
       " (name = LogitDistLoss, instances = [logit_dist_loss], ...)\n",
       " (name = PeriodicLoss, instances = [periodic_loss], ...)\n",
       " (name = QuantileLoss, instances = [quantile_loss], ...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "measures(m -> m.target_scitype <: AbstractVector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
